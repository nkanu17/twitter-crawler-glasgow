{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import tweepy \n",
    "from tweepy import API\n",
    "from tweepy import Stream\n",
    "from tweepy import Cursor\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "import pymongo \n",
    "from pymongo import MongoClient\n",
    "import twitter\n",
    "from pprint import pprint\n",
    "#import MongoClient\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import datetime\n",
    "from datasketch import MinHash, MinHashLSH, MinHashLSHForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# # # consumer key, secre, access token, secret\n",
    "consumer_key = 'IhUBGNHl7MiOBUEYfOK5aowxd'\n",
    "consumer_secret = '0Hptp62enFQm3BJmmcdlD6UqU2I5qcllW4ZUGicuo7kfjyrW3w'\n",
    "access_token = '1047073360474247168-bdgc58jJh9qGq9l9iBXag1KWYrFCge'\n",
    "access_secret = 'f2lqVPyXtPG4AF3Cp9EusAThFIBaE9Cc1iMeu57vNRGKf'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # connecting mongo\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.tweet_db\n",
    "twit_col = db.twit_col\n",
    "geo_search = db.geo_search\n",
    "geo_stream = db.geo_stream\n",
    "api_stream = db.tweet_stream\n",
    "## LSH \n",
    "lsh_m1 = db.lsh_m1\n",
    "lsh_m2 = db.lsh_m2\n",
    "## LSH Cursors\n",
    "m1_cursor = lsh_m1.find()\n",
    "m2_cursor = lsh_m2.find()\n",
    "geoCount = 0\n",
    "streamingCount = 0\n",
    "\n",
    "## each row represent one of the 6 ten minute sessions\n",
    "# first column = # of retweets\n",
    "# second column = # of quotes\n",
    "# third column = # of redundant tweets\n",
    "# fourth column = # geo tagged data from Glasgow\n",
    "# fifth column =  # total geo tagged data\n",
    "# sixth column =  total tweets\n",
    "total_count = np.zeros((6,6))\n",
    "topic_count = np.zeros((6,6))\n",
    "search_count = np.zeros((6,6))\n",
    "geo_count = np.zeros((6,6))\n",
    "\n",
    "# # # Twitter Credentials\n",
    "class TwitterAuthenticator():\n",
    "    \n",
    "    def authenticateTwitter(self):\n",
    "        \n",
    "        auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "        return auth\n",
    "# # # Twitter Search API\n",
    "class TwitterSearch():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.auth = TwitterAuthenticator().authenticateTwitter()\n",
    "        self.twitterClient = API(self.auth)\n",
    "        \n",
    "        #self.twitterUser = twitterUser\n",
    "    \n",
    "    def geoSearch(self, geoCode, maxTweets):\n",
    "        tweets = []\n",
    "        redundant_tweets = 0\n",
    "\n",
    "        i=0\n",
    "        start_time = datetime.datetime.now()\n",
    "        end_time = start_time + datetime.timedelta(0,120)\n",
    "            \n",
    "        while end_time > datetime.datetime.now():\n",
    "\n",
    "            for tweet in Cursor(api.search, q=\"\", geocode = \"%f,%f,%dkm\" % (geoCode[0], geoCode[1], geoCode[2])).items(maxTweets):\n",
    "\n",
    "                #column 0 = retweets, 1 = quotes, 2 = redundant, 3 = glasgow, 4 = geo total, 5 = all tweets\n",
    "\n",
    "                #incrementing retweets counts\n",
    "                total_count[i,0] += tweet.retweet_count\n",
    "                search_count[i,0] += tweet.retweet_count\n",
    "\n",
    "\n",
    "                #incrementing glasgow count\n",
    "                total_count[i,3] += 1\n",
    "                search_count[i,3] += 1\n",
    "\n",
    "                #incrementing geo\n",
    "                total_count[i,4] += 1\n",
    "                search_count[i,4] += 1\n",
    "\n",
    "                #incrementing total\n",
    "                total_count[i,5] += 1\n",
    "                search_count[i,5] += 1\n",
    "                \n",
    "\n",
    "                dictionary = {\n",
    "\n",
    "                    'UserName': tweet.user.name,\n",
    "\n",
    "                    'ScreenName': tweet.user.screen_name,\n",
    "                    'id': tweet.id,\n",
    "                    'id_str': tweet.id_str,\n",
    "\n",
    "                    'TweetCreatedAt': tweet.created_at,\n",
    "                    'TweetText': tweet.text,\n",
    "\n",
    "                    'UserLocation': tweet.user.location,\n",
    "                    'TweetCoordinates': tweet.coordinates,\n",
    "                    'Geo': tweet.geo,\n",
    "                    'Place': None,\n",
    "                    'GeoEnabled': tweet.user.geo_enabled,\n",
    "\n",
    "                    'QuoteCount': 0,\n",
    "                    'RetweetCount': tweet.retweet_count,\n",
    "                    'Retweeted': tweet.retweeted,\n",
    "                    'FavoriteCount': tweet.favorite_count,\n",
    "                    'Favorited': tweet.favorited,\n",
    "                    'LanguageCode': tweet.lang,\n",
    "                    'Source': tweet.source,\n",
    "\n",
    "                    'Replied': tweet.in_reply_to_status_id_str\n",
    "                    }\n",
    "                try:\n",
    "\n",
    "                    geo_search.insert(dictionary)\n",
    "                except:\n",
    "                    print(\"mongo ERROR\")\n",
    "                    pass\n",
    "\n",
    "                ### query mongo db to check for redundancy\n",
    "\n",
    "                tweet_cursor = api_stream.find()\n",
    "\n",
    "                for document in tweet_cursor:\n",
    "                    try:\n",
    "                        #print ('--Redundancy check--')\n",
    "\n",
    "                        if document[\"id_str\"] == id_str:\n",
    "\n",
    "                            # counting redundancy\n",
    "                            total_count[i,2] += 1\n",
    "                            search_count[i,2] += 1\n",
    "\n",
    "                            ## if redundant then discount the count for glasgow\n",
    "                            if document[\"UserLocation\"] != None:\n",
    "                                if \"glasgow\" in document[\"UserLocation\"].lower():\n",
    "                                    total_count[i,3] -= 1\n",
    "                                    search_count[i,3] -= 1\n",
    "\n",
    "                    except:\n",
    "\n",
    "\n",
    "                        pass\n",
    "\n",
    "                tweets.append(dictionary)\n",
    "        \n",
    "        np.savetxt('search_count.csv',geo_count,delimiter=',', fmt=\"%s\")\n",
    "\n",
    "           \n",
    "                \n",
    "    \n",
    "#################################################################\n",
    "### Twitter Streamer\n",
    "class TopicStreamer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.twitter_authenticator = TwitterAuthenticator()\n",
    "        \n",
    "    def streamTweets(self, hash_tags, geo_box):\n",
    "        #authentication\n",
    "        listener = TopicListener()\n",
    "        auth = self.twitter_authenticator.authenticateTwitter()\n",
    "        stream = Stream(auth, listener)\n",
    "        \n",
    "        stream.filter(track = hash_tags)\n",
    "\n",
    "#################################################################\n",
    "### Twitter Streamer by location\n",
    "class LocationStreamer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.twitter_authenticator = TwitterAuthenticator()\n",
    "        \n",
    "    def streamTweets(self, hash_tags, geo_box):\n",
    "        #authentication\n",
    "        listener = GeoListener()\n",
    "        auth = self.twitter_authenticator.authenticateTwitter()\n",
    "        stream = Stream(auth, listener)\n",
    "        \n",
    "        stream.filter(locations = geo_box)\n",
    "        \n",
    "        \n",
    "#################################################################\n",
    "# # # Twitter Stream Listener \n",
    "class TopicListener(StreamListener):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        \n",
    "      \n",
    "        for i in range(5):\n",
    "\n",
    "            start_time = datetime.datetime.now()\n",
    "            end_time = start_time + datetime.timedelta(0,600)\n",
    "            \n",
    "            while end_time > datetime.datetime.now():\n",
    "                i+=1\n",
    "                tweet_json = json.loads(data)  \n",
    "\n",
    "                user_name = tweet_json['user']['name']\n",
    "                screen_name = tweet_json['user']['screen_name']\n",
    "                user_id = tweet_json['user']['id']\n",
    "                user_location = tweet_json['user']['location']\n",
    "                geo_enabled = tweet_json['user']['geo_enabled']\n",
    "                if tweet.geo_enabled != None:\n",
    "                    place = (tweet_json['place']['coordinates'])[0]\n",
    "                else:\n",
    "                    place = None\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                #incrementing retweets counts\n",
    "                total_count[i,0] += tweet_json['retweet_count']\n",
    "                topic_count[i,0] += tweet_json['retweet_count']\n",
    "\n",
    "                #incrementing quotes count\n",
    "                total_count[i,1] += tweet_json['quote_count']\n",
    "                topic_count[i,1] += tweet_json['quote_count']\n",
    "\n",
    "                #incrementing glasgow count\n",
    "                if user_location != None:\n",
    "                    if \"Glasgow\" in user_location:\n",
    "                        total_count[i,3] += 1\n",
    "                        topic_count[i,3] += 1\n",
    "\n",
    "                #incrementing geo\n",
    "                if geo_enabled == True:\n",
    "                    total_count[i,4] += 1\n",
    "                    topic_count[i,4] += 1\n",
    "\n",
    "\n",
    "                #incrementing total\n",
    "                total_count[i,5] += 1 \n",
    "                topic_count[i,4] += 1\n",
    "\n",
    "\n",
    "                dictionary = {\n",
    "\n",
    "                        'UserName': user_name,\n",
    "                        'ScreenName': screen_name,\n",
    "                        'id': user_id,\n",
    "                        'id_str': tweet_json['id_str'],\n",
    "\n",
    "                        'TweetCreatedAt': tweet_json['created_at'],\n",
    "                        'TweetText': tweet_json['text'],\n",
    "\n",
    "                        'UserLocation': user_location,\n",
    "                        'TweetCoordinates': tweet_json['coordinates'],\n",
    "                        'Geo': tweet_json['geo'],\n",
    "                        'Place': place,\n",
    "                        'GeoEnabled': geo_enabled,\n",
    "                        \n",
    "                        'QuoteCount': tweet_json['quote_count'],\n",
    "                        'RetweetCount': tweet_json['retweet_count'],\n",
    "                        'Retweeted': tweet_json['retweeted'],\n",
    "                        'FavoriteCount': tweet_json['favorite_count'],\n",
    "                        'Favorited': tweet_json['favorited'],\n",
    "                        'LanguageCode': tweet_json['lang'],\n",
    "                        'Source': tweet_json['source'],\n",
    "\n",
    "                        'Replied': tweet_json['in_reply_to_status_id_str']\n",
    "                       }\n",
    "                try:\n",
    "                        api_stream.insert(dictionary)\n",
    "                except:\n",
    "                        print(\"mongo ERROR\")\n",
    "                        pass\n",
    "\n",
    "                np.savetxt('topic_count.csv',topic_count,delimiter=',', fmt=\"%s\")\n",
    "                if time.time() > end_time:\n",
    "                    break\n",
    "    \n",
    "# # # Twitter Stream Listener \n",
    "class GeoListener(StreamListener):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def on_data(self, data):\n",
    "               \n",
    "        for i in range(5):\n",
    "            start_time = datetime.datetime.now()\n",
    "            end_time = start_time + datetime.timedelta(0,600)\n",
    "\n",
    "            while end_time > datetime.datetime.now():\n",
    "                tweet_json = json.loads(data)  \n",
    "\n",
    "                user_name = tweet_json['user']['name']\n",
    "                screen_name = tweet_json['user']['screen_name']\n",
    "                user_id = tweet_json['user']['id']\n",
    "                user_location = tweet_json['user']['location']\n",
    "                geo_enabled = tweet_json['user']['geo_enabled']\n",
    "                if tweet.geo_enabled != None:\n",
    "                    place = (tweet_json['place']['coordinates'])[0]\n",
    "                else:\n",
    "                    place = None\n",
    "\n",
    "                #incrementing retweets counts\n",
    "                total_count[i,0] += tweet_json['retweet_count']\n",
    "                geo_count[i,0] += tweet_json['retweet_count']\n",
    "                #incrementing quotes count\n",
    "                total_count[i,1] += tweet_json['quote_count']\n",
    "                geo_count[i,1] += tweet_json['quote_count']\n",
    "                #incrementing glasgow count\n",
    "                if \"glasgow\" in user_location.lower():\n",
    "                    total_count[i,3] += 1\n",
    "                    geo_count[i,1] += tweet_json['quote_count']\n",
    "                #incrementing geo\n",
    "                if geo_enabled == True:\n",
    "                    total_count[i,4] += 1\n",
    "                    geo_count[i,1] += tweet_json['quote_count']\n",
    "                #incrementing total\n",
    "                total_count[i,5] += 1 \n",
    "                geo_count[i,1] += tweet_json['quote_count']\n",
    "\n",
    "                #adding to dictionary before sending it\n",
    "                dictionary = {\n",
    "\n",
    "                        'UserName': user_name,\n",
    "                        'ScreenName': screen_name,\n",
    "                        'id': user_id,\n",
    "                        'id_str': tweet_json['id_str'],\n",
    "\n",
    "                        'TweetCreatedAt': tweet_json['created_at'],\n",
    "                        'TweetText': tweet_json['text'],\n",
    "\n",
    "                        'UserLocation': user_location,\n",
    "                        'TweetCoordinates': tweet_json['coordinates'],\n",
    "                        'Geo': tweet_json['geo'],\n",
    "                        'Place': place,\n",
    "                        'GeoEnabled': geo_enabled,\n",
    "\n",
    "                        'QuoteCount': tweet_json['quote_count'],\n",
    "                        'RetweetCount': tweet_json['retweet_count'],\n",
    "                        'Retweeted': tweet_json['retweeted'],\n",
    "                        'FavoriteCount': tweet_json['favorite_count'],\n",
    "                        'Favorited': tweet_json['favorited'],\n",
    "                        'LanguageCode': tweet_json['lang'],\n",
    "                        'Source': tweet_json['source'],\n",
    "\n",
    "                        'Replied': tweet_json['in_reply_to_status_id_str']\n",
    "                       }\n",
    "                try:\n",
    "                        geo_stream.insert(dictionary)\n",
    "                except:\n",
    "                        print(\"mongo ERROR\")\n",
    "                        pass\n",
    "\n",
    "                tweet_cursor = twit_col.find()\n",
    "                user_cursor = twit_col.distinct(\"id\")\n",
    "\n",
    "                for document in tweet_cursor:\n",
    "                    try:\n",
    "                        print ('--Redundancy check--')\n",
    "\n",
    "                        if document[\"id_str\"] == id_str:\n",
    "                            print ('id_str:', document[\"id_str\"])\n",
    "                            print ('found a match')\n",
    "\n",
    "                            # counting redundancy\n",
    "                            total_count[i,2] += 1\n",
    "                            geo_count[i,2] += 1\n",
    "\n",
    "                            ## if redundant then discount the count for glasgow\n",
    "                            if \"glasgow\" in document[\"UserLocation\"].lower():\n",
    "                                total_count[i,3] -= 1\n",
    "                                geo_count[i,3] -= 1\n",
    "\n",
    "                    except:\n",
    "                        error = \"ERROR\"\n",
    "\n",
    "                        pass\n",
    "\n",
    "\n",
    "    def on_error(self, status):\n",
    "        if status == 420:\n",
    "            return False\n",
    "        print(status)\n",
    "        \n",
    "# # # Saving the counts of retweets, quotes, redundant tweets, glasgow tweets, \n",
    "# # # geo true tweets and total tweets\n",
    "class SaveCounts():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        np.savetxt('total_count.csv',total_count,delimiter=',', fmt=\"%s\")\n",
    "        np.savetxt('topic_count.csv',topic_count,delimiter=',', fmt=\"%s\")\n",
    "        np.savetxt('geo_count.csv',geo_count,delimiter=',', fmt=\"%s\")\n",
    "        np.savetxt('search_count.csv',search_count,delimiter=',', fmt=\"%s\")\n",
    "    \n",
    "# # # MAIN calls streaming functions and grouping\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    geo_code = [55.8642, -4.2518, 10] # for search api\n",
    "    geo_box = [-10.6147114784,50.0038872941,1.8031525989,50.0038872941] # bounding box for location filter \n",
    "    maxTweets = 2500\n",
    "    hash_tags = [\"glasgow\"] # topics for streaming\n",
    "\n",
    "    # # # twitter topic stream api\n",
    "   \n",
    "    twitter_streamer = TopicStreamer()\n",
    "    twitter_streamer.streamTweets(hash_tags, geo_box)\n",
    "    \n",
    "    # # # twitter location streamer\n",
    "    twitter_streamer = LocationStreamer()\n",
    "    twitter_streamer.streamTweets(hash_tags, geo_box)                                     \n",
    "                  \n",
    "    # # # twitter search api\n",
    "    twitterClient = TwitterSearch()\n",
    "    twitterClient.geoSearch(geo_code, maxTweets)\n",
    "    \n",
    "    # # # Process counts and build charts \n",
    "    saveCounts = SaveCounts()\n",
    "    saveCounts\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# The following is going to take a 6x6 matrix CSV file and perform data analysis\n",
    "# The CSV was created during the streaming and rest calls\n",
    "#\n",
    "# each row represent one of the 6 ten minute sessions\n",
    "\n",
    "# # # Read in CSV containing all of the count data and build histograms for all\n",
    "# each row represent one of the 6 ten minute sessions\n",
    "class DataAnalysis():\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.data = np.loadtxt(\"C:/Users/Abhi/Downloads/total_count1.csv\", delimiter=',') # comma separated\n",
    "        \n",
    "        self.time_period = np.arange(1,7)\n",
    "        \n",
    "        self.retweets = self.data[:,0]\n",
    "        self.quotes = self.data[:,1]\n",
    "        self.redundant = self.data[:,2]\n",
    "        self.glasgow = self.data[:,3]\n",
    "        self.geo_total = self.data[:,4]\n",
    "        self.total = self.data[:,5]\n",
    "        \n",
    "    # first column = # of retweets  \n",
    "    def quotesRetweets(self):\n",
    "        fig = plt.figure()\n",
    "        axes = plt.subplot(1,1,1)\n",
    "        barWidth=0.25\n",
    "        \n",
    "        r1 = np.arange(len(self.time_period))\n",
    "        r2 = [x + barWidth for x in r1]\n",
    "        r3 = [x + barWidth for x in r2]\n",
    "        \n",
    "        plt.bar(r1, self.total, color='red', width=barWidth, edgecolor='white', label='Total tweets')\n",
    "        plt.bar(r2, self.retweets, color='yellow', width=barWidth, edgecolor='white', label='Retweets')\n",
    "        plt.bar(r3, self.quotes, color='green', width=barWidth, edgecolor='white', label='Quotes')\n",
    "\n",
    "        plt.xticks([r + barWidth for r in range(len(self.time_period))], ['1', '2', '3', '4', '5','6'])\n",
    "        plt.legend()\n",
    "        axes.set_title('Total tweets compared to number of Retweets and Quotes')\n",
    "        axes.set_ylabel('Number of Tweets')\n",
    "        axes.set_xlabel('Time Period (ten mins)')\n",
    "        plt.show()\n",
    "        \n",
    "    # third column = # of redundant tweets\n",
    "    def redundantCount(self):\n",
    "        fig = plt.figure()\n",
    "        axes = plt.subplot(1,1,1)\n",
    "        barWidth=0.50\n",
    "        \n",
    "        r1 = np.arange(len(self.time_period))\n",
    "        r2 = [x + barWidth for x in r1]\n",
    "        \n",
    "        plt.bar(r1, self.total, color='red', width=barWidth, edgecolor='white', label='Total tweets')\n",
    "        plt.bar(r2, self.redundant, color='green', width=barWidth, edgecolor='white', label='Redundant tweets')\n",
    "        \n",
    "        plt.xlabel('Total tweets vs redundant tweets', fontweight='bold')\n",
    "        plt.xticks([r + barWidth for r in range(len(self.time_period))], ['1', '2', '3', '4', '5','6'])\n",
    "        plt.legend()\n",
    "        axes.set_title('Total tweets vs Redundant tweets')\n",
    "        axes.set_ylabel('Number of Tweets')\n",
    "        axes.set_xlabel('Time Period (ten mins)')\n",
    "        plt.show()\n",
    "    \n",
    "    # fourth column = # geo tagged data from Glasgow\n",
    "    def glasgowCount(self):\n",
    "        fig = plt.figure()\n",
    "        axes = plt.subplot(1,1,1)\n",
    "        plt.bar(self.time_period, self.glasgow)\n",
    "        \n",
    "        axes.set_title('Total tweets from Glasgow per time period')\n",
    "        axes.set_ylabel('Number of Tweets')\n",
    "        axes.set_xlabel('Time Period (ten mins)')\n",
    "        plt.show()\n",
    "    # sixth column =  total tweets\n",
    "    def totalCount(self):\n",
    "        fig = plt.figure()\n",
    "        axes = plt.subplot(1,1,1)\n",
    "        plt.bar(self.time_period, self.total)\n",
    "        \n",
    "        axes.set_title('Total number of tweets per time period')\n",
    "        axes.set_ylabel('Number of Tweets')\n",
    "        axes.set_xlabel('Time Period (ten mins)')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "# # # MAIN\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #calling data analysis class to plot data\n",
    "    analyze = DataAnalysis()\n",
    "    analyze.quotesRetweets()\n",
    "    analyze.redundantCount()\n",
    "    analyze.glasgowCount()\n",
    "    analyze.totalCount()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymongo \n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from datasketch import MinHash, MinHashLSH, MinHashLSHForest\n",
    "\n",
    "\n",
    "#count = 0\n",
    "##query mongodb existing collection for say 500 tweets, create two new collections with those 500 tweets\n",
    "\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.tweet_db\n",
    "tweet_collection = db.tweet_collection\n",
    "# test_lsh = db.test_lsh\n",
    "lsh_m1 = db.lsh_m1\n",
    "lsh_m2 = db.lsh_m2\n",
    "# lsh_test = db.lsh_test\n",
    "\n",
    "# tweet_cursor = test_lsh.find()\n",
    "m1_cursor = lsh_m1.find()\n",
    "m2_cursor = lsh_m2.find()\n",
    "# print(tweet_cursor.count())\n",
    "\n",
    "#Number of Permutations\n",
    "permutations = 128\n",
    "\n",
    "#Number of Recommendations to return\n",
    "#num_recommendations = 1\n",
    "\n",
    "# first index with id string and text\n",
    "# then tokenize the text\n",
    "# class IndexMongo(): \n",
    "\n",
    "# then send the table as m1 to lsh (lsh.insert)\n",
    "            \n",
    "\n",
    "# then identical or duplicated dataset\n",
    "\n",
    "# use a loop to go through each tweet \n",
    "# query that tweet with lsh\n",
    "\n",
    "# for all the matches, send them to a new collection\n",
    "# for all the matches, delete them from LSH and dataset\n",
    "# def insertTest:\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    tokens = text.lower()\n",
    "    tokens = tokens.split()\n",
    "    return tokens\n",
    "\n",
    "def get_lsh(perms):\n",
    "    \n",
    "    counter = 0\n",
    "    groups = []\n",
    "    group_results = []\n",
    "    minhash = []\n",
    "    lsh = MinHashLSH(threshold=0.5,num_perm = 128)\n",
    "    m1 = MinHash(num_perm=perms)\n",
    "    m2 = MinHash(num_perm=perms)\n",
    "    \n",
    "    for x in m1_cursor:\n",
    "        id1 = x['id_str']\n",
    "        for word in x['text']:\n",
    "            m1.update(word.encode('utf8'))\n",
    "        lsh.insert(id1,m1)\n",
    "        \n",
    "    for y in m2_cursor:\n",
    "        id2 = y['id_str']\n",
    "        if lsh.__contains__(id2):\n",
    "            for word in y['text']:\n",
    "                m2.update(word.encode('utf8'))\n",
    "            result = lsh.query(m2)\n",
    "            lsh.remove(id2)\n",
    "            groups.append(counter+1)\n",
    "            group_results.append(len(result))\n",
    "\n",
    "            for key in result:\n",
    "                if lsh.__contains__(key):\n",
    "                    print(\"Similar tweet with id: \" + str(key))\n",
    "                    lsh.remove(key)\n",
    "            counter += 1\n",
    "\n",
    "    return groups, group_results\n",
    "\n",
    "#plots groupings\n",
    "def plot(group, group_lists):\n",
    "    fig = plt.figure()\n",
    "    axes = plt.subplot(1,1,1)\n",
    "    barWidth=0.50\n",
    "\n",
    "   \n",
    "    plt.bar(group, group_lists)\n",
    "        \n",
    "        \n",
    "    axes.set_title('LSH Total Tweets per Group')\n",
    "    axes.set_ylabel('Group Number')\n",
    "    axes.set_xlabel('Size')\n",
    "    plt.show()\n",
    "    \n",
    "# # # Main    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # performing LSH\n",
    "    group, group_lists = get_lsh(128)\n",
    "    \n",
    "    #plotting groupings\n",
    "    plot(group, group_lists)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
